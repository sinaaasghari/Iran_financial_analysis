{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_df_R98Data DataFrame created with shape: (18430, 17)\n",
      "df_df_R98P1 DataFrame created with shape: (64296, 10)\n",
      "df_df_R98P2 DataFrame created with shape: (18430, 45)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sheet \u001b[38;5;129;01min\u001b[39;00m sheetNames:\n\u001b[0;32m     19\u001b[0m     df_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdf_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msheet\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Create a dynamic DataFrame name\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m     \u001b[38;5;28mglobals\u001b[39m()[df_name] \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msheet\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m     dataframes_list\u001b[38;5;241m.\u001b[39mappend(df_name)\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m DataFrame created with shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mglobals\u001b[39m()[df_name]\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Poumi008\\.conda\\envs\\bootCamp\\lib\\site-packages\\pandas\\io\\excel\\_base.py:508\u001b[0m, in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[0;32m    502\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    503\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    504\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    505\u001b[0m     )\n\u001b[0;32m    507\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 508\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    509\u001b[0m \u001b[43m        \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msheet_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    510\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    511\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    512\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    513\u001b[0m \u001b[43m        \u001b[49m\u001b[43musecols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musecols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    514\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    515\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconverters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconverters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    516\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrue_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrue_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    517\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfalse_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfalse_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskiprows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskiprows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    519\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnrows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    520\u001b[0m \u001b[43m        \u001b[49m\u001b[43mna_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_default_na\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_default_na\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m        \u001b[49m\u001b[43mna_filter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_filter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    525\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdate_parser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_parser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[43m        \u001b[49m\u001b[43mthousands\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthousands\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    528\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecimal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecimal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    529\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcomment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    530\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskipfooter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipfooter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    531\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    532\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    533\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    534\u001b[0m     \u001b[38;5;66;03m# make sure to close opened file handles\u001b[39;00m\n\u001b[0;32m    535\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m should_close:\n",
      "File \u001b[1;32mc:\\Users\\Poumi008\\.conda\\envs\\bootCamp\\lib\\site-packages\\pandas\\io\\excel\\_base.py:1616\u001b[0m, in \u001b[0;36mExcelFile.parse\u001b[1;34m(self, sheet_name, header, names, index_col, usecols, converters, true_values, false_values, skiprows, nrows, na_values, parse_dates, date_parser, date_format, thousands, comment, skipfooter, dtype_backend, **kwds)\u001b[0m\n\u001b[0;32m   1576\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse\u001b[39m(\n\u001b[0;32m   1577\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1578\u001b[0m     sheet_name: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1596\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds,\n\u001b[0;32m   1597\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, DataFrame] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mint\u001b[39m, DataFrame]:\n\u001b[0;32m   1598\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1599\u001b[0m \u001b[38;5;124;03m    Parse specified sheet(s) into a DataFrame.\u001b[39;00m\n\u001b[0;32m   1600\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1614\u001b[0m \u001b[38;5;124;03m    >>> file.parse()  # doctest: +SKIP\u001b[39;00m\n\u001b[0;32m   1615\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1616\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mparse(\n\u001b[0;32m   1617\u001b[0m         sheet_name\u001b[38;5;241m=\u001b[39msheet_name,\n\u001b[0;32m   1618\u001b[0m         header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[0;32m   1619\u001b[0m         names\u001b[38;5;241m=\u001b[39mnames,\n\u001b[0;32m   1620\u001b[0m         index_col\u001b[38;5;241m=\u001b[39mindex_col,\n\u001b[0;32m   1621\u001b[0m         usecols\u001b[38;5;241m=\u001b[39musecols,\n\u001b[0;32m   1622\u001b[0m         converters\u001b[38;5;241m=\u001b[39mconverters,\n\u001b[0;32m   1623\u001b[0m         true_values\u001b[38;5;241m=\u001b[39mtrue_values,\n\u001b[0;32m   1624\u001b[0m         false_values\u001b[38;5;241m=\u001b[39mfalse_values,\n\u001b[0;32m   1625\u001b[0m         skiprows\u001b[38;5;241m=\u001b[39mskiprows,\n\u001b[0;32m   1626\u001b[0m         nrows\u001b[38;5;241m=\u001b[39mnrows,\n\u001b[0;32m   1627\u001b[0m         na_values\u001b[38;5;241m=\u001b[39mna_values,\n\u001b[0;32m   1628\u001b[0m         parse_dates\u001b[38;5;241m=\u001b[39mparse_dates,\n\u001b[0;32m   1629\u001b[0m         date_parser\u001b[38;5;241m=\u001b[39mdate_parser,\n\u001b[0;32m   1630\u001b[0m         date_format\u001b[38;5;241m=\u001b[39mdate_format,\n\u001b[0;32m   1631\u001b[0m         thousands\u001b[38;5;241m=\u001b[39mthousands,\n\u001b[0;32m   1632\u001b[0m         comment\u001b[38;5;241m=\u001b[39mcomment,\n\u001b[0;32m   1633\u001b[0m         skipfooter\u001b[38;5;241m=\u001b[39mskipfooter,\n\u001b[0;32m   1634\u001b[0m         dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1635\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds,\n\u001b[0;32m   1636\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Poumi008\\.conda\\envs\\bootCamp\\lib\\site-packages\\pandas\\io\\excel\\_base.py:778\u001b[0m, in \u001b[0;36mBaseExcelReader.parse\u001b[1;34m(self, sheet_name, header, names, index_col, usecols, dtype, true_values, false_values, skiprows, nrows, na_values, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, dtype_backend, **kwds)\u001b[0m\n\u001b[0;32m    775\u001b[0m     sheet \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_sheet_by_index(asheetname)\n\u001b[0;32m    777\u001b[0m file_rows_needed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_calc_rows(header, index_col, skiprows, nrows)\n\u001b[1;32m--> 778\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_sheet_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43msheet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_rows_needed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    779\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(sheet, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclose\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;66;03m# pyxlsb opens two TemporaryFiles\u001b[39;00m\n\u001b[0;32m    781\u001b[0m     sheet\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\Poumi008\\.conda\\envs\\bootCamp\\lib\\site-packages\\pandas\\io\\excel\\_openpyxl.py:615\u001b[0m, in \u001b[0;36mOpenpyxlReader.get_sheet_data\u001b[1;34m(self, sheet, file_rows_needed)\u001b[0m\n\u001b[0;32m    613\u001b[0m data: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mlist\u001b[39m[Scalar]] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    614\u001b[0m last_row_with_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 615\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row_number, row \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(sheet\u001b[38;5;241m.\u001b[39mrows):\n\u001b[0;32m    616\u001b[0m     converted_row \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_cell(cell) \u001b[38;5;28;01mfor\u001b[39;00m cell \u001b[38;5;129;01min\u001b[39;00m row]\n\u001b[0;32m    617\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m converted_row \u001b[38;5;129;01mand\u001b[39;00m converted_row[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    618\u001b[0m         \u001b[38;5;66;03m# trim trailing empty elements\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Poumi008\\.conda\\envs\\bootCamp\\lib\\site-packages\\openpyxl\\worksheet\\_read_only.py:85\u001b[0m, in \u001b[0;36mReadOnlyWorksheet._cells_by_row\u001b[1;34m(self, min_col, min_row, max_col, max_row, values_only)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_source() \u001b[38;5;28;01mas\u001b[39;00m src:\n\u001b[0;32m     78\u001b[0m     parser \u001b[38;5;241m=\u001b[39m WorkSheetParser(src,\n\u001b[0;32m     79\u001b[0m                              \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shared_strings,\n\u001b[0;32m     80\u001b[0m                              data_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39mdata_only,\n\u001b[0;32m     81\u001b[0m                              epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39mepoch,\n\u001b[0;32m     82\u001b[0m                              date_formats\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39m_date_formats,\n\u001b[0;32m     83\u001b[0m                              timedelta_formats\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39m_timedelta_formats)\n\u001b[1;32m---> 85\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx, row \u001b[38;5;129;01min\u001b[39;00m parser\u001b[38;5;241m.\u001b[39mparse():\n\u001b[0;32m     86\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m max_row \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m idx \u001b[38;5;241m>\u001b[39m max_row:\n\u001b[0;32m     87\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Poumi008\\.conda\\envs\\bootCamp\\lib\\site-packages\\openpyxl\\worksheet\\_reader.py:156\u001b[0m, in \u001b[0;36mWorkSheetParser.parse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    137\u001b[0m properties \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    138\u001b[0m     PRINT_TAG: (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprint_options\u001b[39m\u001b[38;5;124m'\u001b[39m, PrintOptions),\n\u001b[0;32m    139\u001b[0m     MARGINS_TAG: (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpage_margins\u001b[39m\u001b[38;5;124m'\u001b[39m, PageMargins),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    151\u001b[0m \n\u001b[0;32m    152\u001b[0m }\n\u001b[0;32m    154\u001b[0m it \u001b[38;5;241m=\u001b[39m iterparse(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource) \u001b[38;5;66;03m# add a finaliser to close the source when this becomes possible\u001b[39;00m\n\u001b[1;32m--> 156\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, element \u001b[38;5;129;01min\u001b[39;00m it:\n\u001b[0;32m    157\u001b[0m     tag_name \u001b[38;5;241m=\u001b[39m element\u001b[38;5;241m.\u001b[39mtag\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tag_name \u001b[38;5;129;01min\u001b[39;00m dispatcher:\n",
      "File \u001b[1;32mc:\\Users\\Poumi008\\.conda\\envs\\bootCamp\\lib\\xml\\etree\\ElementTree.py:1255\u001b[0m, in \u001b[0;36miterparse.<locals>.iterator\u001b[1;34m(source)\u001b[0m\n\u001b[0;32m   1253\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m pullparser\u001b[38;5;241m.\u001b[39mread_events()\n\u001b[0;32m   1254\u001b[0m \u001b[38;5;66;03m# load event buffer\u001b[39;00m\n\u001b[1;32m-> 1255\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43msource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1256\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[0;32m   1257\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Poumi008\\.conda\\envs\\bootCamp\\lib\\zipfile.py:926\u001b[0m, in \u001b[0;36mZipExtFile.read\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m    924\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    925\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m n \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eof:\n\u001b[1;32m--> 926\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    927\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(data):\n\u001b[0;32m    928\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_readbuffer \u001b[38;5;241m=\u001b[39m data\n",
      "File \u001b[1;32mc:\\Users\\Poumi008\\.conda\\envs\\bootCamp\\lib\\zipfile.py:994\u001b[0m, in \u001b[0;36mZipExtFile._read1\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m    992\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decompressor\u001b[38;5;241m.\u001b[39munconsumed_tail\n\u001b[0;32m    993\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlen\u001b[39m(data):\n\u001b[1;32m--> 994\u001b[0m         data \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    995\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    996\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read2(n)\n",
      "File \u001b[1;32mc:\\Users\\Poumi008\\.conda\\envs\\bootCamp\\lib\\zipfile.py:1026\u001b[0m, in \u001b[0;36mZipExtFile._read2\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m   1023\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(n, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mMIN_READ_SIZE)\n\u001b[0;32m   1024\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(n, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compress_left)\n\u001b[1;32m-> 1026\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fileobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1027\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compress_left \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(data)\n\u001b[0;32m   1028\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n",
      "File \u001b[1;32mc:\\Users\\Poumi008\\.conda\\envs\\bootCamp\\lib\\zipfile.py:747\u001b[0m, in \u001b[0;36m_SharedFile.read\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m    745\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pos)\n\u001b[0;32m    746\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file\u001b[38;5;241m.\u001b[39mread(n)\n\u001b[1;32m--> 747\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtell\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "file_path = ['R98.xlsx', 'R99.xlsx',\n",
    "             'R1401.xlsx', 'R1400.xlsx',\n",
    "             'U98.xlsx', 'U99.xlsx',\n",
    "             'U1401.xlsx', 'U1400.xlsx']\n",
    "\n",
    "# Map for accessinng dataFrames of each year easily\n",
    "file_to_dfs_map = {}\n",
    "\n",
    "for path in file_path: \n",
    "    \n",
    "    file_identifier = path.split('/')[-1].split('.')[0]\n",
    "    dataframes_list = []\n",
    "\n",
    "    excel_file = pd.ExcelFile(path)\n",
    "    sheetNames = excel_file.sheet_names\n",
    "    \n",
    "\n",
    "    for sheet in sheetNames:\n",
    "        df_name = f'df_{sheet}'  # Create a dynamic DataFrame name\n",
    "        globals()[df_name] = pd.read_excel(path, sheet_name=sheet)\n",
    "        dataframes_list.append(df_name)\n",
    "        print(f'{df_name} DataFrame created with shape: {globals()[df_name].shape}')\n",
    "    \n",
    "    file_to_dfs_map[file_identifier] = dataframes_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return a df with index and cols address and value of year for that address in p3_01 to p3_13\n",
    "def outcome_p3_01_13(df_name):\n",
    "    df_output = df_name.groupby(by= ['Address'])['value'].sum().reset_index()\n",
    "    return df_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return a df with index and cols address and value of year for that address in p3_14\n",
    "def outcome_p3_14(df_name):\n",
    "    #for handling '            ' in R1401 p3 s14\n",
    "    df_name['value'] = df_name['value'].replace('            ', 0)\n",
    "    df_name['value'] = pd.to_numeric(df_name['value'])\n",
    "    \n",
    "    df_filtered = df_name[~pd.isna(df_name['value'])]\n",
    "    df_output = df_filtered.groupby(by= 'Address')['value'].sum().reset_index()\n",
    "    return df_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "file_name_list = ['R98', 'R99',\n",
    "             'R1401', 'R1400',\n",
    "             'U98', 'U99',\n",
    "             'U1401', 'U1400']\n",
    "\n",
    "for file_name in file_name_list:\n",
    "    dfs = []\n",
    "    for sheet_page in range(3, 16, 1):\n",
    "        temp_df = globals()[file_to_dfs_map[file_name][sheet_page]]\n",
    "        temp_df = outcome_p3_01_13(temp_df).copy()\n",
    "        temp_df = temp_df.rename(columns={'value': f'value_{sheet_page - 2}'})\n",
    "        dfs.append(temp_df)\n",
    "    temp_df = globals()[file_to_dfs_map[file_name][16]]\n",
    "    temp_df = outcome_p3_14(temp_df).copy()\n",
    "    temp_df = temp_df.rename(columns={'value': f'value_{14}'})\n",
    "    dfs.append(temp_df)\n",
    "    merged_df = reduce(lambda left, right: pd.merge(left, right, on='Address', how='outer'), dfs)\n",
    "    output = pd.DataFrame()\n",
    "    output['Address'] = merged_df['Address']\n",
    "    output['Outcome'] = merged_df.iloc[:, 1:].sum(axis= 1)\n",
    "    output.to_excel(f'outcome{file_name}.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = ['R98.xlsx', 'R99.xlsx',\n",
    "             'R1401.xlsx', 'R1400.xlsx',\n",
    "             'U98.xlsx', 'U99.xlsx',\n",
    "             'U1401.xlsx', 'U1400.xlsx']\n",
    "\n",
    "# Map for accessinng dataFrames of each year easily\n",
    "file_to_dfs_map = {}\n",
    "\n",
    "for path in file_path: \n",
    "    \n",
    "    file_identifier = path.split('/')[-1].split('.')[0]\n",
    "    dataframes_list = []\n",
    "\n",
    "    excel_file = pd.ExcelFile(path)\n",
    "    sheetNames = excel_file.sheet_names\n",
    "    \n",
    "\n",
    "    for sheet in sheetNames:\n",
    "        df_name = f'df_{sheet}'  # Create a dynamic DataFrame name\n",
    "        globals()[df_name] = pd.read_excel(path, sheet_name=sheet)\n",
    "        dataframes_list.append(df_name)\n",
    "        print(f'{df_name} DataFrame created with shape: {globals()[df_name].shape}')\n",
    "    \n",
    "    file_to_dfs_map[file_identifier] = dataframes_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_Sheet1 DataFrame created with shape: (18430, 3)\n",
      "df_Sheet1 DataFrame created with shape: (18251, 3)\n",
      "df_Sheet1 DataFrame created with shape: (18370, 3)\n",
      "df_Sheet1 DataFrame created with shape: (18384, 3)\n",
      "df_Sheet1 DataFrame created with shape: (19898, 3)\n",
      "df_Sheet1 DataFrame created with shape: (19306, 3)\n",
      "df_Sheet1 DataFrame created with shape: (19618, 3)\n",
      "df_Sheet1 DataFrame created with shape: (19567, 3)\n"
     ]
    }
   ],
   "source": [
    "file_path = [r'cost_family/outcomeR98.xlsx', r'cost_family/outcomeR99.xlsx',\n",
    "             r'cost_family/outcomeR1400.xlsx', r'cost_family/outcomeR1401.xlsx',\n",
    "             r'cost_family/outcomeU98.xlsx', r'cost_family/outcomeU99.xlsx',\n",
    "             r'cost_family/outcomeU1400.xlsx', r'cost_family/outcomeU1401.xlsx']\n",
    "\n",
    "# Map for accessinng dataFrames of each year easily\n",
    "file_to_dfs_map = {}\n",
    "\n",
    "for path in file_path: \n",
    "    \n",
    "    file_identifier = path.split('/')[-1].split('.')[0]\n",
    "    dataframes_list = []\n",
    "\n",
    "    excel_file = pd.ExcelFile(path)\n",
    "    sheetNames = excel_file.sheet_names\n",
    "    \n",
    "\n",
    "    for sheet in sheetNames:\n",
    "        df_name = f'df_{sheet}'  # Create a dynamic DataFrame name\n",
    "        globals()[df_name] = pd.read_excel(path, sheet_name=sheet)\n",
    "        dataframes_list.append(df_name)\n",
    "        print(f'{df_name} DataFrame created with shape: {globals()[df_name].shape}')\n",
    "    \n",
    "    file_to_dfs_map[file_identifier] = dataframes_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Address</th>\n",
       "      <th>totall_income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10001000126</td>\n",
       "      <td>19409280000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001000130</td>\n",
       "      <td>6583760000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10001000132</td>\n",
       "      <td>10646320000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10001000135</td>\n",
       "      <td>3278320000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10001000138</td>\n",
       "      <td>9900592000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19552</th>\n",
       "      <td>13006383827</td>\n",
       "      <td>6598880000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19553</th>\n",
       "      <td>13006383832</td>\n",
       "      <td>9576840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19554</th>\n",
       "      <td>13006383835</td>\n",
       "      <td>12011520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19555</th>\n",
       "      <td>13006383838</td>\n",
       "      <td>12757639992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19556</th>\n",
       "      <td>13006383841</td>\n",
       "      <td>7580040000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19557 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Address  totall_income\n",
       "0      10001000126    19409280000\n",
       "1      10001000130     6583760000\n",
       "2      10001000132    10646320000\n",
       "3      10001000135     3278320000\n",
       "4      10001000138     9900592000\n",
       "...            ...            ...\n",
       "19552  13006383827     6598880000\n",
       "19553  13006383832     9576840000\n",
       "19554  13006383835    12011520000\n",
       "19555  13006383838    12757639992\n",
       "19556  13006383841     7580040000\n",
       "\n",
       "[19557 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#merging outcome data of each year by address of family and then sum all years to one dataFrame called df_income_all_year\n",
    "\n",
    "from functools import reduce\n",
    "dfs = []\n",
    "for file_name in file_to_dfs_map.keys():\n",
    "    temp1 = globals()[file_to_dfs_map[file_name][0]].copy()\n",
    "    temp1 = temp1.rename(columns= {'lastincome': f'lastincome_{file_name}'})\n",
    "    dfs.append(temp1)\n",
    "\n",
    "merged_income = reduce(lambda left, right: pd.merge(left, right, on= 'Address', how= 'outer'), dfs)\n",
    "df_income_all_year = pd.DataFrame()\n",
    "df_income_all_year['Address'] = merged_income['Address']\n",
    "df_income_all_year['totall_income'] = merged_income.iloc[:, 1:].sum(axis= 1)\n",
    "df_income_all_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_Sheet1 DataFrame created with shape: (18429, 2)\n",
      "df_Sheet1 DataFrame created with shape: (18250, 2)\n",
      "df_Sheet1 DataFrame created with shape: (18366, 2)\n",
      "df_Sheet1 DataFrame created with shape: (18380, 2)\n",
      "df_Sheet1 DataFrame created with shape: (19893, 2)\n",
      "df_Sheet1 DataFrame created with shape: (19302, 2)\n",
      "df_Sheet1 DataFrame created with shape: (19612, 2)\n",
      "df_Sheet1 DataFrame created with shape: (19557, 2)\n"
     ]
    }
   ],
   "source": [
    "#read cost of families from year 98 to 1401\n",
    "\n",
    "file_path = [r'income_family/R98_output.xlsx', r'income_family/R99_output.xlsx',\n",
    "             r'income_family/R1400_output.xlsx', r'income_family/R1401_output.xlsx',\n",
    "             r'income_family/U98_output.xlsx', r'income_family/U99_output.xlsx',\n",
    "             r'income_family/U1400_output.xlsx', r'income_family/U1401_output.xlsx']\n",
    "\n",
    "# Map for accessinng dataFrames of each year easily\n",
    "file_to_dfs_map = {}\n",
    "\n",
    "for path in file_path: \n",
    "    \n",
    "    file_identifier = path.split('/')[-1].split('.')[0]\n",
    "    dataframes_list = []\n",
    "\n",
    "    excel_file = pd.ExcelFile(path)\n",
    "    sheetNames = excel_file.sheet_names\n",
    "    \n",
    "\n",
    "    for sheet in sheetNames:\n",
    "        df_name = f'df_{sheet}'  # Create a dynamic DataFrame name\n",
    "        globals()[df_name] = pd.read_excel(path, sheet_name=sheet)\n",
    "        dataframes_list.append(df_name)\n",
    "        print(f'{df_name} DataFrame created with shape: {globals()[df_name].shape}')\n",
    "    \n",
    "    file_to_dfs_map[file_identifier] = dataframes_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Address</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10001000126</td>\n",
       "      <td>1218760000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10001000130</td>\n",
       "      <td>153712000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10001000132</td>\n",
       "      <td>163720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>10001000135</td>\n",
       "      <td>137920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>10001000138</td>\n",
       "      <td>653590000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19562</th>\n",
       "      <td>19562</td>\n",
       "      <td>13006383827</td>\n",
       "      <td>425213000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19563</th>\n",
       "      <td>19563</td>\n",
       "      <td>13006383832</td>\n",
       "      <td>2280486000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19564</th>\n",
       "      <td>19564</td>\n",
       "      <td>13006383835</td>\n",
       "      <td>250390000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19565</th>\n",
       "      <td>19565</td>\n",
       "      <td>13006383838</td>\n",
       "      <td>608797000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19566</th>\n",
       "      <td>19566</td>\n",
       "      <td>13006383841</td>\n",
       "      <td>89545000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19567 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0      Address     Outcome\n",
       "0               0  10001000126  1218760000\n",
       "1               1  10001000130   153712000\n",
       "2               2  10001000132   163720000\n",
       "3               3  10001000135   137920000\n",
       "4               4  10001000138   653590000\n",
       "...           ...          ...         ...\n",
       "19562       19562  13006383827   425213000\n",
       "19563       19563  13006383832  2280486000\n",
       "19564       19564  13006383835   250390000\n",
       "19565       19565  13006383838   608797000\n",
       "19566       19566  13006383841    89545000\n",
       "\n",
       "[19567 rows x 3 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "globals()[file_to_dfs_map[list(file_to_dfs_map.keys())[0]][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'outcomeR98': ['df_Sheet1'],\n",
       " 'outcomeR99': ['df_Sheet1'],\n",
       " 'outcomeR1400': ['df_Sheet1'],\n",
       " 'outcomeR1401': ['df_Sheet1'],\n",
       " 'outcomeU98': ['df_Sheet1'],\n",
       " 'outcomeU99': ['df_Sheet1'],\n",
       " 'outcomeU1400': ['df_Sheet1'],\n",
       " 'outcomeU1401': ['df_Sheet1']}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_to_dfs_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Address</th>\n",
       "      <th>totall_income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10001000126</td>\n",
       "      <td>9750080000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001000130</td>\n",
       "      <td>1229696000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10001000132</td>\n",
       "      <td>1309760000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10001000135</td>\n",
       "      <td>1103360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10001000138</td>\n",
       "      <td>5228720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19562</th>\n",
       "      <td>13006383827</td>\n",
       "      <td>3401704000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19563</th>\n",
       "      <td>13006383832</td>\n",
       "      <td>18243888000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19564</th>\n",
       "      <td>13006383835</td>\n",
       "      <td>2003120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19565</th>\n",
       "      <td>13006383838</td>\n",
       "      <td>4870376000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19566</th>\n",
       "      <td>13006383841</td>\n",
       "      <td>716360000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19567 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Address  totall_income\n",
       "0      10001000126     9750080000\n",
       "1      10001000130     1229696000\n",
       "2      10001000132     1309760000\n",
       "3      10001000135     1103360000\n",
       "4      10001000138     5228720000\n",
       "...            ...            ...\n",
       "19562  13006383827     3401704000\n",
       "19563  13006383832    18243888000\n",
       "19564  13006383835     2003120000\n",
       "19565  13006383838     4870376000\n",
       "19566  13006383841      716360000\n",
       "\n",
       "[19567 rows x 2 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#merging outcome data of each year by address of family and then sum all years to one dataFrame called df_income_all_year\n",
    "\n",
    "from functools import reduce\n",
    "dfs = []\n",
    "for file_name in file_to_dfs_map.keys():\n",
    "    temp1 = globals()[file_to_dfs_map[file_name][0]].drop(columns= ['Unnamed: 0']).copy()\n",
    "    temp1 = temp1.rename(columns= {'Outcome': f'Outcome{file_name}'})\n",
    "    dfs.append(temp1)\n",
    "\n",
    "merged_cost = reduce(lambda left, right: pd.merge(left, right, on= 'Address', how= 'outer'), dfs)\n",
    "df_cost_all_year = pd.DataFrame()\n",
    "df_cost_all_year['Address'] = merged_cost['Address']\n",
    "df_cost_all_year['totall_income'] = merged_cost.iloc[:, 1:].sum(axis= 1)\n",
    "df_cost_all_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_income_cost_family = pd.merge(df_income_all_year, df_cost_all_year, on= 'Address', how= 'outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of df_income_all_year = 19557\n",
      "length of df_cost_all_year = 19567\n",
      "length of df_income_cost_family = 19567\n"
     ]
    }
   ],
   "source": [
    "print(f'length of df_income_all_year = {len(df_income_all_year)}')\n",
    "print(f'length of df_cost_all_year = {len(df_cost_all_year)}')\n",
    "print(f'length of df_income_cost_family = {len(df_income_cost_family)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Address</th>\n",
       "      <th>totall_income_x</th>\n",
       "      <th>totall_income_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10001000126</td>\n",
       "      <td>1.940928e+10</td>\n",
       "      <td>9750080000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001000130</td>\n",
       "      <td>6.583760e+09</td>\n",
       "      <td>1229696000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10001000132</td>\n",
       "      <td>1.064632e+10</td>\n",
       "      <td>1309760000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10001000135</td>\n",
       "      <td>3.278320e+09</td>\n",
       "      <td>1103360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10001000138</td>\n",
       "      <td>9.900592e+09</td>\n",
       "      <td>5228720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19562</th>\n",
       "      <td>13006383827</td>\n",
       "      <td>6.598880e+09</td>\n",
       "      <td>3401704000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19563</th>\n",
       "      <td>13006383832</td>\n",
       "      <td>9.576840e+09</td>\n",
       "      <td>18243888000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19564</th>\n",
       "      <td>13006383835</td>\n",
       "      <td>1.201152e+10</td>\n",
       "      <td>2003120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19565</th>\n",
       "      <td>13006383838</td>\n",
       "      <td>1.275764e+10</td>\n",
       "      <td>4870376000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19566</th>\n",
       "      <td>13006383841</td>\n",
       "      <td>7.580040e+09</td>\n",
       "      <td>716360000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19567 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Address  totall_income_x  totall_income_y\n",
       "0      10001000126     1.940928e+10       9750080000\n",
       "1      10001000130     6.583760e+09       1229696000\n",
       "2      10001000132     1.064632e+10       1309760000\n",
       "3      10001000135     3.278320e+09       1103360000\n",
       "4      10001000138     9.900592e+09       5228720000\n",
       "...            ...              ...              ...\n",
       "19562  13006383827     6.598880e+09       3401704000\n",
       "19563  13006383832     9.576840e+09      18243888000\n",
       "19564  13006383835     1.201152e+10       2003120000\n",
       "19565  13006383838     1.275764e+10       4870376000\n",
       "19566  13006383841     7.580040e+09        716360000\n",
       "\n",
       "[19567 rows x 3 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_income_cost_family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bootCamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
